# üìä RA1 - An√°lisis de Videojuegos con Pandas y PySpark

## üìñ Introducci√≥n

Este proyecto implementa un proceso completo de **an√°lisis de datos de videojuegos** utilizando dos enfoques complementarios:
- **Pandas**: Para procesamiento en memoria y an√°lisis exploratorio
- **PySpark**: Para procesamiento distribuido y escalabilidad

El objetivo principal es realizar la **exploraci√≥n, limpieza, transformaci√≥n y carga (ETL)** de un dataset de videojuegos, culminando en la creaci√≥n de un **data warehouse dimensional** almacenado en bases de datos SQLite.

---

## üîÑ Flujo Completo del Proyecto

El proyecto sigue un flujo estructurado en 5 fases principales, procesando datos desde su origen hasta un modelo de data warehouse optimizado para consultas anal√≠ticas:

![Flujo completo del proyecto](RA1_VIDEOGAMES_PROJECT_FLOW_FULL.drawio.png)

### Descripci√≥n del Flujo

**CAPA ORIGEN**: Dataset bruto `videogames.csv` que contiene informaci√≥n de miles de videojuegos con m√∫ltiples atributos (nombre, plataforma, g√©nero, puntuaciones, ventas, ingresos).

**FASE 1 - Exploraci√≥n y Limpieza (Pandas)**:
1. Carga del CSV desde m√∫ltiples rutas posibles
2. An√°lisis de tipos de datos y detecci√≥n de valores nulos
3. Limpieza exhaustiva: valores faltantes, duplicados
4. Normalizaci√≥n de columnas: metascore, user_score, ventas, ingresos
5. Output: DataFrame limpio (`df_clean`)

**FASE 2 - Procesamiento con PySpark**:
1. Creaci√≥n de SparkSession para procesamiento distribuido
2. Carga del CSV original o limpio
3. Transformaciones: selecci√≥n, filtrado, columnas num√©ricas
4. Agregaciones por g√©nero y plataforma
5. Joins para an√°lisis cruzado (`df_joined`)

**FASE 3 - Proceso ETL con Pandas**:
- **Extracci√≥n**: Copia de `df_clean`
- **Transformaci√≥n**: Nuevas columnas calculadas (score_promedio, categoria_ventas, ingreso_por_copia), agregaciones (df_by_genre, df_by_platform)
- **Carga**: Base de datos SQLite `warehouse_pandas.db` con tablas de apoyo

**FASE 4 - Proceso ETL con PySpark**:
- **Extracci√≥n**: `df_etl` = copia de `df_joined`
- **Transformaci√≥n dimensional**: Creaci√≥n de dim_genre (g√©nero), dim_platform (plataforma), fact_videogames con m√©tricas agregadas
- **Carga**: Base de datos SQLite `warehouse_pyspark.db` con modelo estrella

**FASE 5 - Modelo de Data Warehouse (SQL)**:
- Scripts SQL que definen la estructura del modelo estrella
- `modelo_datawarehouse_pandas.sql`: CREATE TABLE para las tablas de Pandas
- `modelo_datawarehouse_pyspark.sql`: CREATE TABLE con definici√≥n de PK y FK para el modelo estrella
- Definici√≥n de claves primarias y for√°neas para mantener integridad referencial


## üßπ Fase 1: Exploraci√≥n y Limpieza con Pandas

### Proceso de Limpieza de Datos

La limpieza de datos es fundamental para garantizar la calidad del an√°lisis. En este proyecto se aplicaron m√∫ltiples t√©cnicas de limpieza:

#### 1. **Detecci√≥n de Valores Especiales**
Se identificaron y reemplazaron valores que representaban datos faltantes pero no eran reconocidos como `NaN`:
```python
specials = ['?', 'N/A', 'Unknown', 'unknown', '', ' ', 'nan', 'NaN']
df_clean = df_clean.replace(specials, np.nan)
```

**Justificaci√≥n**: Los datasets del mundo real contienen m√∫ltiples representaciones de valores faltantes que deben estandarizarse para un tratamiento consistente.

#### 2. **Eliminaci√≥n de Duplicados**
```python
df_clean = df_clean.drop_duplicates()
```

**Justificaci√≥n**: Los duplicados pueden sesgar estad√≠sticas y an√°lisis. Se eliminan para garantizar la integridad de los datos.

#### 3. **Tratamiento Inteligente de Valores Faltantes**

La estrategia adoptada fue escalonada seg√∫n el porcentaje de valores nulos:

- **Columnas con >60% de nulos**: Se eliminan completamente
  - **Justificaci√≥n**: Columnas con tantos valores faltantes no aportan informaci√≥n √∫til y pueden generar bias
  
- **Filas con >60% de nulos**: Se eliminan
  - **Justificaci√≥n**: Registros incompletos que no permiten an√°lisis confiable

- **Imputaci√≥n de valores num√©ricos**: Se usa la **mediana**
  ```python
  for col in num_cols:
      med = df_clean[col].median()
      df_clean[col] = df_clean[col].fillna(med)
  ```
  - **Justificaci√≥n**: La mediana es robusta ante outliers, a diferencia de la media

- **Imputaci√≥n de valores categ√≥ricos**: Se usa la **moda** (valor m√°s frecuente)
  ```python
  for col in cat_cols:
      moda = df_clean[col].mode()
      if not moda.empty:
          df_clean[col] = df_clean[col].fillna(moda.iloc[0])
  ```
  - **Justificaci√≥n**: La moda mantiene la distribuci√≥n original de las categor√≠as

#### 4. **Normalizaci√≥n de Texto y Estandarizaci√≥n**
```python
# Limpieza de espacios en blanco
df_clean[col] = df_clean[col].astype(str).str.strip()

# Unificaci√≥n de plataformas
platform_map = {
    'ps': 'PS', 'playstation': 'PS', 'ps4': 'PS', 'ps5': 'PS',
    'xbox': 'Xbox', 'xbox one': 'Xbox', 'xbox series x': 'Xbox',
    'pc': 'PC', 'windows': 'PC',
    'mobile': 'Mobile',
    'nintendo switch': 'Switch', 'switch': 'Switch'
}
```

**Justificaci√≥n**: 
- Elimina inconsistencias en la entrada de datos
- Reduce la cardinalidad de variables categ√≥ricas
- Facilita agrupaciones y an√°lisis posteriores
- Mejora la calidad de las visualizaciones

#### 5. **Transformaci√≥n de Columnas Num√©ricas**

Se crearon funciones especializadas para parsear diferentes formatos encontrados en los datos:

##### `parse_cost()`: Precios de videojuegos
- Convierte: `'$59.99'`, `'‚Ç¨49,99'`, `'free'` ‚Üí valores num√©ricos
- Maneja m√∫ltiples divisas y formatos de separadores decimales
- **Justificaci√≥n**: Los precios vienen en formatos diversos que necesitan estandarizaci√≥n para c√°lculos posteriores

##### `parse_score()`: Puntuaciones
- Normaliza escalas diferentes: `'8.5/10'` ‚Üí `85.0`, `'47.7'` ‚Üí `47.7`
- **Justificaci√≥n**: Las puntuaciones pueden estar en escala 0-10 o 0-100; se unifican a 0-100 para comparabilidad

##### `parse_millions()`: Ventas e ingresos
- Convierte: `'10M'` ‚Üí `10.0`, `'1.5B'` ‚Üí `1500.0` (millones)
- **Justificaci√≥n**: Estandariza unidades (millones/billones) para c√°lculos matem√°ticos correctos

#### 6. **Escalado de Variables Num√©ricas (Min-Max Normalization)**
```python
df_clean[col + '_scaled'] = (df_clean[col] - col_min) / (col_max - col_min)
```

**Justificaci√≥n**: 
- Normaliza valores a rango [0, 1]
- Facilita comparaciones entre variables de diferentes escalas
- Prepara datos para posibles modelos de machine learning
- Mejora la interpretabilidad de visualizaciones

### Resultado de la Limpieza

Despu√©s de aplicar todas estas t√©cnicas:
- **0 valores NaN** en el dataset final
- **100% de datos v√°lidos** y listos para an√°lisis
- **Formatos estandarizados** en todas las columnas
- **Nuevas columnas derivadas** con informaci√≥n calculada

---

## ‚ö° Fase 2: Procesamiento con PySpark

### ¬øPor qu√© PySpark?

PySpark se utiliza para demostrar capacidades de procesamiento distribuido que ser√≠an esenciales al escalar el an√°lisis a datasets de mayor tama√±o (cientos de GB o TB).

### Transformaciones Clave Aplicadas

#### 1. **Selecci√≥n y Filtrado Inteligente**
```python
df_filtered = (
    df_numeric
    .filter(col("metascore_num").isNotNull())
    .filter(col("copies_sold_millions_num").isNotNull())
)
```

**Justificaci√≥n**: Se filtran registros con valores nulos en m√©tricas clave (puntuaciones y ventas) porque son esenciales para el an√°lisis de rendimiento comercial. Sin estas m√©tricas, un videojuego no puede ser evaluado correctamente.

#### 2. **Agregaci√≥n por G√©nero**
```python
df_by_genre = (
    df_filtered
    .groupBy("genre")
    .agg(
        count("*").alias("num_juegos"),
        avg("metascore_num").alias("metascore_medio"),
        sum("copies_sold_millions_num").alias("ventas_totales")
    )
)
```

**Justificaci√≥n**: 
- **Identifica g√©neros dominantes**: Cu√°les son los m√°s populares
- **An√°lisis de calidad**: G√©neros con mejores puntuaciones
- **Rendimiento comercial**: G√©neros m√°s rentables
- **Decisiones de negocio**: Qu√© g√©neros priorizar en desarrollos futuros

#### 3. **Creaci√≥n de Columnas Calculadas (Feature Engineering)**
```python
df_with_new_cols = df_filtered.withColumn(
    "categoria_ventas",
    when(col("copies_sold_millions_num") >= 5, "Alto")
    .when(col("copies_sold_millions_num") >= 1, "Medio")
    .otherwise("Bajo")
)
```

**Justificaci√≥n**: 
- **Segmentaci√≥n clara**: Facilita an√°lisis por categor√≠as de rendimiento
- **Interpretabilidad**: "Alto/Medio/Bajo" es m√°s intuitivo que n√∫meros crudos
- **An√°lisis comparativo**: Permite agrupar juegos de rendimiento similar
- **Insights de negocio**: Identifica blockbusters vs. juegos de nicho

#### 4. **Join y Enriquecimiento de Datos**
```python
df_joined = (
    df_with_new_cols
    .join(df_platform_stats, on="platform", how="left")
)
```

**Justificaci√≥n**: 
- **Contexto por plataforma**: Cada juego se compara con el promedio de su plataforma
- **Benchmarking**: Identifica juegos que superan/no alcanzan el promedio de su plataforma
- **An√°lisis relativo**: Un juego con 2M ventas en Mobile es exitoso, pero en PS5 ser√≠a bajo
- **Optimizaci√≥n de queries**: Se pre-calcula informaci√≥n agregada para evitar c√°lculos repetitivos

---

## üîÑ Fase 3: ETL con Pandas

### Proceso ETL Detallado

#### **Extracci√≥n (E)**
Se reutiliza el DataFrame limpio de la Fase 1, garantizando que los datos ya est√°n validados y normalizados. Esto evita reprocesamiento innecesario.

#### **Transformaci√≥n (T)**

##### Nuevas Columnas Calculadas:

1. **`score_promedio`**: Promedio entre metascore (cr√≠ticos) y user_score (usuarios)
   ```python
   df_etl['score_promedio'] = (df_etl['metascore_num'] + df_etl['user_score_num']) / 2
   ```
   - **Justificaci√≥n**: Combina opini√≥n profesional y popular. Un juego debe satisfacer tanto a cr√≠ticos como a jugadores para ser considerado excelente.

2. **`categoria_ventas`**: Clasificaci√≥n de rendimiento comercial
   - Bajo: < 1M copias
   - Moderado: 1-5M copias
   - Exitoso: 5-10M copias
   - Blockbuster: > 10M copias
   - **Justificaci√≥n**: Segmentaci√≥n est√°ndar de la industria del videojuego. Permite an√°lisis estratificado del mercado.

3. **`ingreso_por_copia`**: Revenue / Copias vendidas
   ```python
   df_etl['ingreso_por_copia'] = df_etl['revenue_millions_usd'] / df_etl['copies_sold_millions']
   ```
   - **Justificaci√≥n**: M√©trica de monetizaci√≥n efectiva. Identifica juegos que generan m√°s valor por unidad vendida (ej: juegos con DLCs, microtransacciones).

##### Agregaciones Estrat√©gicas:

- **`by_genre`**: Total de juegos, promedios de puntuaciones, suma de ventas e ingresos por g√©nero
  - **Uso**: An√°lisis de portfolio, identificaci√≥n de g√©neros estrat√©gicos

- **`by_platform`**: Total de juegos, suma de ventas e ingresos por plataforma
  - **Uso**: Decisiones de lanzamiento multiplataforma, an√°lisis de market share

#### **Carga (L)**
```python
df_etl.to_sql('videogames', conn, if_exists='replace', index=False)
df_by_genre.to_sql('by_genre', conn, if_exists='replace', index=False)
df_by_platform.to_sql('by_platform', conn, if_exists='replace', index=False)
```

**Resultado**: Base de datos `warehouse_pandas.db` con 3 tablas optimizadas para consultas anal√≠ticas r√°pidas.

---

## üåü Fase 4: ETL con PySpark y Modelo Dimensional

### Modelo Dimensional Estrella

El modelo dimensional es el coraz√≥n del data warehouse. Se implementa un **esquema estrella** que optimiza las consultas anal√≠ticas:

![Modelo Dimensional Estrella](RA1_VIDEOGAMES_STAR_MODEL_V2.drawio.png)

### Estructura del Modelo

#### üìä **Dimensi√≥n 1: `dim_genre` (G√©nero)**

**Campos:**
- `genre_id`: Clave primaria auto-generada (PK)
- `genre`: Nombre del g√©nero (Action, RPG, Sports, Strategy, etc.)

**Justificaci√≥n de la Dimensi√≥n:**
- **Alto poder anal√≠tico**: Los g√©neros son la clasificaci√≥n principal en la industria del videojuego
- **Baja cardinalidad**: ~10-20 g√©neros √∫nicos, ideal para una dimensi√≥n
- **Estabilidad**: Los g√©neros no cambian frecuentemente en el tiempo
- **Casos de uso cr√≠ticos**:
  - An√°lisis de tendencias: ¬øQu√© g√©neros est√°n creciendo?
  - Comparaci√≥n de rendimiento: ¬øQu√© g√©neros son m√°s rentables?
  - Estrategia de producto: ¬øEn qu√© g√©nero invertir en desarrollo?
  - Market research: ¬øQu√© g√©neros prefieren los jugadores actuales?

**Por qu√© es una dimensi√≥n clave**: El g√©nero determina la audiencia objetivo, el estilo de juego, el presupuesto de desarrollo t√≠pico y las expectativas de ventas. Es imposible analizar el mercado de videojuegos sin esta dimensi√≥n.

#### üìä **Dimensi√≥n 2: `dim_platform` (Plataforma)**

**Campos:**
- `platform_id`: Clave primaria auto-generada (PK)
- `platform`: Nombre de la plataforma (PS5, Xbox, PC, Switch, Mobile, etc.)

**Justificaci√≥n de la Dimensi√≥n:**
- **Relevancia comercial cr√≠tica**: Las plataformas definen ecosistemas completos de mercado
- **Cardinalidad media**: ~15-30 plataformas activas, perfecta para una dimensi√≥n
- **Impacto en ventas**: Cada plataforma tiene diferente base de usuarios, precios, y modelos de negocio
- **Casos de uso cr√≠ticos**:
  - An√°lisis de market share: ¬øQu√© plataforma domina el mercado?
  - Estrategia de lanzamiento: ¬øLanzar exclusivo o multiplataforma?
  - Comparaci√≥n de rendimiento: ¬øEn qu√© plataforma venden m√°s nuestros juegos?
  - Tendencias tecnol√≥gicas: ¬øEst√° creciendo Mobile vs. Console?

**Por qu√© es una dimensi√≥n clave**: La plataforma determina el modelo de distribuci√≥n (f√≠sica/digital), el precio t√≠pico, la demograf√≠a de usuarios, y las capacidades t√©cnicas. Es esencial para decisiones estrat√©gicas de negocio.

#### üé≤ **Tabla de Hechos: `fact_videogames`**

**Claves For√°neas (Foreign Keys):**
- `genre_id`: Enlace a dim_genre
- `platform_id`: Enlace a dim_platform

**M√©tricas (Measures) - Datos Cuantitativos:**
- `metascore_num`: Puntuaci√≥n de cr√≠ticos (0-100)
- `copies_sold_millions_num`: Millones de copias vendidas
- `num_juegos_plataforma`: Contexto agregado de la plataforma
- `metascore_medio_plataforma`: Benchmark de calidad de la plataforma
- `ventas_totales_plataforma`: Potencial total de mercado de la plataforma

**Atributos Descriptivos:**
- `name`: Nombre del videojuego
- `categoria_ventas`: Segmentaci√≥n comercial (Alto/Medio/Bajo)
- `categoria_calidad`: Segmentaci√≥n por calidad (Excelente/Buena/Regular/Mala)

**Caracter√≠sticas del Dise√±o:**
- **Granularidad**: Un registro por juego (nivel m√°s at√≥mico posible)
- **Desnormalizaci√≥n controlada**: Se incluyen estad√≠sticas agregadas de plataforma para evitar re-c√°lculos frecuentes en consultas
- **Balance**: Combina datos transaccionales (ventas) con m√©tricas derivadas (categor√≠as) y contexto agregado

### Ventajas del Esquema Estrella Implementado

#### 1. **Consultas Simples y R√°pidas**
Las queries anal√≠ticas requieren solo 1-2 JOINs, en lugar de navegar por m√∫ltiples niveles de normalizaci√≥n:

```sql
-- Ejemplo: Ventas totales por g√©nero y plataforma (solo 2 JOINs)
SELECT 
    g.genre,
    p.platform,
    SUM(f.copies_sold_millions_num) as ventas_totales
FROM fact_videogames f
JOIN dim_genre g ON f.genre_id = g.genre_id
JOIN dim_platform p ON f.platform_id = p.platform_id
GROUP BY g.genre, p.platform;
```

#### 2. **Rendimiento Optimizado**
- **√çndices eficientes**: Las claves primarias y for√°neas se indexan autom√°ticamente
- **Dimensiones en cach√©**: Las tablas dim_genre y dim_platform son peque√±as y caben en memoria
- **Lectura secuencial**: La tabla de hechos se lee de forma √≥ptima sin saltos

#### 3. **Mantenimiento Simplificado**
- **Actualizaci√≥n de dimensiones**: Cambiar "PS4" a "PS" solo afecta a dim_platform
- **Independencia de tablas**: Agregar nuevos atributos a dimensiones no altera la tabla de hechos
- **Escalabilidad**: Millones de registros en fact_videogames con performance constante

#### 4. **Flexibilidad Anal√≠tica**
El modelo permite responder preguntas de negocio complejas con consultas simples:
- An√°lisis temporal de g√©neros
- Comparaci√≥n entre plataformas
- Identificaci√≥n de blockbusters por segmento
- An√°lisis de correlaci√≥n calidad-ventas

### Proceso ETL de PySpark

#### **Extracci√≥n (E)**
```python
df_etl = df_joined.cache()
```
Se reutiliza el DataFrame enriquecido de la Fase 2, que ya incluye transformaciones complejas y joins.

#### **Transformaci√≥n (T) - Creaci√≥n del Modelo Dimensional**

```python
# DIMENSI√ìN 1: G√©nero
dim_genre = (
    df_etl
    .select("genre")
    .distinct()
    .withColumn("genre_id", monotonically_increasing_id())
)

# DIMENSI√ìN 2: Plataforma
dim_platform = (
    df_etl
    .select("platform")
    .distinct()
    .withColumn("platform_id", monotonically_increasing_id())
)

# TABLA DE HECHOS: Videojuegos con claves for√°neas
fact_videogames = (
    df_etl
    .join(dim_genre, on="genre", how="left")
    .join(dim_platform, on="platform", how="left")
    .select("fact_id", "genre_id", "platform_id", "name", 
            "metascore_num", "copies_sold_millions_num", ...)
)
```

**T√©cnicas aplicadas**:
- `monotonically_increasing_id()`: Genera IDs √∫nicos y crecientes para las claves primarias
- `distinct()`: Elimina duplicados para obtener solo valores √∫nicos en dimensiones
- Joins de tipo LEFT: Garantiza que no se pierdan registros de la tabla de hechos

#### **Carga (L)**
```python
# Conversi√≥n a Pandas para carga en SQLite
dim_genre_pd = dim_genre.toPandas()
dim_platform_pd = dim_platform.toPandas()
fact_videogames_pd = fact_videogames.toPandas()

# Carga en SQLite
conn = sqlite3.connect('warehouse_pyspark.db')
dim_genre_pd.to_sql('dim_genre', conn, if_exists='replace')
dim_platform_pd.to_sql('dim_platform', conn, if_exists='replace')
fact_videogames_pd.to_sql('fact_videogames', conn, if_exists='replace')
```

**Resultado**: Base de datos `warehouse_pyspark.db` con modelo estrella completo y optimizado.

---

## üîç Ejemplos de Consultas Anal√≠ticas

El modelo dimensional permite responder preguntas de negocio complejas con consultas SQL simples. A continuaci√≥n se muestran ejemplos pr√°cticos:

### **2 consultas para Pandas**
**PANDAS 1 ‚Äì G√©neros m√°s rentables**

```sql
SELECT 
    g.genre_name AS genre,
    COUNT(*) AS total_juegos,
    ROUND(SUM(f.copies_sold_millions_num), 2) AS ventas_totales_millones,
    ROUND(AVG(f.metascore_num), 2) AS puntuacion_promedio
FROM fact_videogame f
JOIN dim_genre g 
    ON f.genre_id = g.genre_id
GROUP BY g.genre_name
ORDER BY ventas_totales_millones DESC
LIMIT 10;
```

**PANDAS 2 ‚Äì Plataforma con mejor rendimiento promedio**

```sql
SELECT 
    p.platform_name AS platform,
    COUNT(*) AS num_juegos,
    ROUND(AVG(f.metascore_num), 2) AS metascore_promedio,
    ROUND(AVG(f.copies_sold_millions_num), 2) AS ventas_promedio_por_juego
FROM fact_videogame f
JOIN dim_platform p 
    ON f.platform_id = p.platform_id
GROUP BY p.platform_name
ORDER BY metascore_promedio DESC;
```

---

### **2 consultas para PySpark**

**PYSPARK 1 ‚Äì Juegos que superan el promedio de su plataforma**

```sql
SELECT 
    f.name,
    p.platform,
    f.metascore_num,
    f.metascore_medio_plataforma,
    (f.metascore_num - f.metascore_medio_plataforma) AS diferencia
FROM fact_videogames f
JOIN dim_platform p 
    ON f.platform_id = p.platform_id
WHERE f.metascore_num > f.metascore_medio_plataforma
ORDER BY diferencia DESC
LIMIT 20;
```

**PYSPARK 2 ‚Äì Correlaci√≥n entre calidad y ventas**

```sql
SELECT 
    f.categoria_calidad,
    COUNT(*) AS num_juegos,
    ROUND(AVG(f.copies_sold_millions_num), 2) AS ventas_promedio,
    ROUND(AVG(f.metascore_num), 2) AS puntuacion_promedio
FROM fact_videogames f
GROUP BY f.categoria_calidad
ORDER BY 
    CASE f.categoria_calidad
        WHEN 'Excelente' THEN 1
        WHEN 'Buena' THEN 2
        WHEN 'Regular' THEN 3
        WHEN 'Mala' THEN 4
    END;
```

---

## üõ†Ô∏è Decisiones T√©cnicas y Justificaci√≥n

### Comparaci√≥n: Pandas vs PySpark

| Aspecto | Pandas | PySpark | Decisi√≥n en este proyecto |
|---------|--------|---------|---------------------------|
| **Tama√±o de datos** | < 10 GB | > 100 GB | Pandas suficiente para dataset actual (~500MB) |
| **Procesamiento** | En memoria (RAM) | Distribuido (cluster) | Pandas m√°s r√°pido para este caso |
| **Sintaxis** | Muy intuitiva | Similar a SQL | Pandas para exploraci√≥n, PySpark para demostrar escalabilidad |
| **Agregaciones** | R√°pido en datasets peque√±os | √ìptimo en Big Data | PySpark usado para agregaciones complejas |
| **Joins** | Eficiente < 1M filas | Eficiente a cualquier escala | Ambos v√°lidos aqu√≠ |
| **Integraci√≥n SQLite** | Nativa con `to_sql()` | Requiere conversi√≥n a Pandas | Pandas para carga final |

**Conclusi√≥n**: Se usan **ambos** para demostrar competencias complementarias:
- **Pandas**: Limpieza exhaustiva, an√°lisis exploratorio, carga r√°pida a SQLite
- **PySpark**: Transformaciones distribuibles, preparaci√≥n para producci√≥n a gran escala

### Estrategias de Limpieza Aplicadas

| Problema Detectado | Soluci√≥n Adoptada | Alternativa Descartada | Justificaci√≥n de la Decisi√≥n |
|-------------------|-------------------|------------------------|------------------------------|
| Valores faltantes en columnas clave | Imputaci√≥n con mediana/moda | Eliminaci√≥n de filas completas | Preserva 80-90% de los datos vs. perder 50%+ |
| Columnas con >60% nulos | Eliminaci√≥n de columna completa | Imputaci√≥n avanzada (ML) | Coste-beneficio: demasiado esfuerzo para poca informaci√≥n confiable |
| Duplicados exactos | Eliminaci√≥n inmediata | Deduplicaci√≥n parcial (fuzzy) | Los duplicados exactos son claramente errores de carga |
| Formatos inconsistentes | Funciones de parsing especializadas | Regex gen√©rico universal | Mayor precisi√≥n y control sobre casos edge espec√≠ficos |
| Escalas diferentes (0-10 vs 0-100) | Normalizaci√≥n a escala com√∫n | Dejar como est√°n | Facilita comparaciones directas y visualizaciones |
| Outliers extremos | Mantenimiento de valores reales | Eliminaci√≥n/winsorizaci√≥n | Los outliers son informativos (ej: GTA V con 185M ventas es real) |