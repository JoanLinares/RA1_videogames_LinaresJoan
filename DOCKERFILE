# Imagen base con Python 3.11
FROM python:3.11-slim

# Establecer directorio de trabajo
WORKDIR /app

# Instalar dependencias del sistema necesarias para PySpark y Java
RUN apt-get update && apt-get install -y \
    openjdk-21-jre-headless \
    wget \
    procps \
    && rm -rf /var/lib/apt/lists/*

# Establecer variables de entorno para Java y Spark
ENV JAVA_HOME=/usr/lib/jvm/java-21-openjdk-amd64
ENV SPARK_HOME=/opt/spark
ENV PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
ENV PYSPARK_PYTHON=python3
ENV PYSPARK_DRIVER_PYTHON=jupyter
ENV PYSPARK_DRIVER_PYTHON_OPTS='notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root'

# Descargar e instalar Apache Spark
RUN wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz \
    && tar xzf spark-3.5.0-bin-hadoop3.tgz -C /opt \
    && mv /opt/spark-3.5.0-bin-hadoop3 /opt/spark \
    && rm spark-3.5.0-bin-hadoop3.tgz

# Instalar dependencias de Python
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir \
    pandas==2.1.4 \
    numpy==1.26.2 \
    pyspark==3.5.0 \
    SQLAlchemy==2.0.23 \
    jupyter==1.0.0 \
    notebook==7.0.6 \
    ipykernel==6.27.1 \
    ipywidgets==8.1.1 \
    matplotlib==3.8.2 \
    seaborn==0.13.0 \
    plotly==5.18.0

# Copiar el contenido del proyecto
COPY . .

# Crear directorios necesarios
RUN mkdir -p /app/warehouse /app/notebooks /app/data

# Exponer puerto para Jupyter Notebook
EXPOSE 8888

# Comando por defecto: iniciar Jupyter Notebook
CMD ["jupyter", "notebook", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root", "--NotebookApp.token=", "--NotebookApp.password="]